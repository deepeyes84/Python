{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e24b2c",
   "metadata": {},
   "source": [
    "## 07 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4805010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀는 선형 회귀 방식을 분류에 적용한 알고리즘이다.\n",
    "# 로지스틱 회귀가 선형 회귀와 다른 점은 시그모이드(Sigmoid) 함수 최적선을 찾고\n",
    "# 이 시그모이드 함수의 반환 값을 확률로 간주해 확률에 따라 분류를 결정한다는 것이다.\n",
    "\n",
    "# 많은 자연, 사회 현상에서 특정 변수의 확률 값은 선형이 아니라 S자 커브 형태를 가진다.\n",
    "# 시그모이드 함수의 정의는 y = 1 / 1+e-x 이다.\n",
    "# 시그모이드 함수는 x 값이 +, -로 아무리 작아져도 y 값은 항상 0과 1 사이 값을 반환한다.\n",
    "# x 값이 커지면 1에 근사하며 x값이 작아지면 0에 근사한다. x가 0일 때는 0.5 이다.\n",
    "\n",
    "# 로지스틱 회귀는 선형 회귀 방식을 기반하되 시그모이드 함수를 이용해 분류를 수행하는 회귀이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0286de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e00aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 회귀 계열의 로지스틱 회귀는 데이터의 정규 분포도에 따라 예측 성능 영향을\n",
    "# 받을 수 있으므로 데이터에 먼저 정규 분포 형태의 표준 스케일링을 적용 한 뒤에 데이터 세트를 분리한다.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# StandardScaler( )로 평균이 0, 분산이 1인 데이터로 변환\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, cancer.target,\n",
    "                                                   test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d323cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.977\n",
      "roc_auc: 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행.\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_preds = lr_clf.predict(X_test)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print('accuracy: {:0.3f}'.format(accuracy_score(y_test, lr_preds)))\n",
    "print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test, lr_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9bd1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런 LogisticRegression 클래스의 주요 하이퍼 파라미터는 penalty와 C가 있다.\n",
    "# penalty는 규제(Regularization)의 유형을 설정하며 'l2'와 'l1'이 있다.\n",
    "# C는 규제 강도를 조절하는 alpha값의 역수이다. 즉, C = 1/alpha 이다.\n",
    "# C 값이 작을수록 규제 강도가 크다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415b69c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:{'C': 1, 'penalty': 'l2'}, 최적 평균 정확도:0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adam/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adam/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/adam/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/adam/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.94555834        nan 0.97364708        nan 0.97539218        nan\n",
      " 0.97539218        nan 0.97011974        nan 0.96661097        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'penalty':['l2', 'l1'],\n",
    "        'C':[0.01, 0.1, 1, 1, 5, 10]}\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, \n",
    "                                                  grid_clf.best_score_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
