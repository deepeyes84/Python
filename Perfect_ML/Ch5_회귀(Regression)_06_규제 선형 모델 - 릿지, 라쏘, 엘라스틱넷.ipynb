{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a12c90d",
   "metadata": {},
   "source": [
    "## 06 규제 선형 모델 - 릿지, 라쏘, 엘라스틱넷"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea053c4f",
   "metadata": {},
   "source": [
    "### 규제 선형 모델의 개요 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0887abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 모델은 적절히 데이터에 적합하면서도 회귀 계수가 기하급수적으로 증가하는 것을 제어할 수 있어야 한다.\n",
    "# 이전까지 선형 모델의 비용 함수는 RSS를 최소화 하는, 즉 실제 값과 예측 값의 차이를 최소화 하는 것만 고려 했다.\n",
    "# 그러나 보니 학습 데이터에 지나치게 맞추게 되고, 회귀 계수가 쉽게 커졌다.\n",
    "# 이럴 경우 변동성이 오히려 심해져서 테스트 데이터 세트에서는 예측 성능이 저하되기 쉽다.\n",
    "# 이를 반영해 비용 함수는 학습 데이터의 잔차 오류 값을 최소로 하는 RSS 최소화 방법과\n",
    "# 과적합을 방지하기 위해 회귀 계수 값이 커지지 않도록 하는 방법이 서로 균형을 이뤄야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc89443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비용 함수 목표 = Min(RSS(W) + alpha*||W||2^2)\n",
    "# 여기에서 alpha는 학습 데이터 적합 정도와 회귀 계수 값의 크기 제어를 수행하는 튜닝 파라미터이다.\n",
    "# alpha 값을 크게 하면 비용 함수는 회귀 계수 W의 값을 작게 해 과적합을 개선할 수 있으며\n",
    "# alpha 값을 작게 하면 회귀 계수 W의 값이 커져도 어느 정도 상쇄가 가능하므로 학습 데이터 적합을\n",
    "# 더 개선할 수 있다.\n",
    "# 즉, alpha를 0에서부터 자속적으로 값을 증가시키면 회귀 계수 값의 크기를 감소시킬 수 있다.\n",
    "# 이처럼 비횽 함수에 alpha 값으로 페널티를 부여해 회귀 계수 값의 크기를 감소시켜 과적합을 개선하는 방식을\n",
    "# 규제(Regularization)라고 부른다.\n",
    "\n",
    "# L2 규제(Ridge)는 W의 제곱에 대해 페널티를 부여하는 방식을 말한다.\n",
    "# L1 규제(Lasso)는 W의 절대값에 대해 페널티를 부여하는 방식이다. \n",
    "# L1 규제를 적용하면 영향력이 크지 않은 회귀 계수 값을 0으로 변환 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2af5a8",
   "metadata": {},
   "source": [
    "### 릿지 회귀(L2 규제)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사이킷런은 Ridge 클래스를 통해 릿지 회귀를 구현한다.\n",
    "# Ridge 클래스의 주요 생성 파라미터는 alpha이며, 이는 릿지 회귀의 alpha L2 규제 계수에 해당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd448e4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# alpha=10으로 설정해 릿지 회귀 수행.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ridge \u001b[38;5;241m=\u001b[39m Ridge(alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m neg_mse_scores \u001b[38;5;241m=\u001b[39m cross_val_score(ridge, \u001b[43mX_data\u001b[49m, y_target, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      7\u001b[0m rmse_scores  \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m neg_mse_scores)\n\u001b[1;32m      8\u001b[0m avg_rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(rmse_scores)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 앞의 LinearRegression예제에서 분할한 feature 데이터 셋인 X_data과 Target 데이터 셋인 Y_target 데이터셋을 그대로 이용 \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# boston 데이타셋 로드\n",
    "boston = load_boston()\n",
    "\n",
    "# boston 데이타셋 DataFrame 변환 \n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "\n",
    "# boston dataset의 target array는 주택 가격임. 이를 PRICE 컬럼으로 DataFrame에 추가함. \n",
    "bostonDF['PRICE'] = boston.target\n",
    "print('Boston 데이타셋 크기 :',bostonDF.shape)\n",
    "\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "# alpha=10으로 설정해 릿지 회귀 수행.\n",
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 3))\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba91768c",
   "metadata": {},
   "source": [
    "#### alpha값을 0, 0.1, 1, 10, 100으로 변경하면서 RMSE 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 릿지에 사용될 alpha 파라미터의 값을 정의\n",
    "alphas = [0, 0.1, 1, 10, 100]\n",
    "\n",
    "# alphas list 값을 반복하면서 alpha에 다른 평균 rmse를 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    \n",
    "    # cross_val_score를 이용해 5 폴드의 평균 RMSE를 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds의 평균 RMSE: {1:.3f}'.format(alpha, avg_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51a337d",
   "metadata": {},
   "source": [
    "#### 각 alpha에 따른 회귀 계수 값을 시각화, 각 alpha값 별로 plt.subplots로 맷플롯립 축 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617d3c06",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 각 alpha에 따른 회귀 계수 값을 시각화 하기 위해 5개의 열로 된 맷플롯립 축 생성\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m6\u001b[39m), nrows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 각 alpha에 따른 회귀 계수 값을 데이터로 저장하기 위한 DataFrame 생성\u001b[39;00m\n\u001b[1;32m      5\u001b[0m coeff_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# 각 alpha에 따른 회귀 계수 값을 시각화 하기 위해 5개의 열로 된 맷플롯립 축 생성\n",
    "fig, axes = plt.subplots(figsize=(18, 6), nrows=1, ncols=5)\n",
    "\n",
    "# 각 alpha에 따른 회귀 계수 값을 데이터로 저장하기 위한 DataFrame 생성\n",
    "coeff_df = pd.DataFrame()\n",
    "\n",
    "# alphas 리스트 값을 차례로 입력해 회귀 계수 값 시각화 및 데이터 저장. pos는 axis의 위치 지정\n",
    "for pos, alpha in enumerate(alphas):\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_data, y_target)\n",
    "    \n",
    "    # alpha에 따른 피처별로 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.\n",
    "    coeff = pd.Series(data=ridge.coef_, index=X_data.columns)\n",
    "    colname = 'alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    \n",
    "    # 막대 그래프로 각 alpha 값에서의 회귀 계수를 시각화. 회귀 계수값이 높은 순으로 표현\n",
    "    coeff = coeff.sort_values(ascending=False)\n",
    "    axs[pos].set_title(colname)\n",
    "    axs[pos].set_xlim(-3, 6)\n",
    "    sns.barplot(x=coeff.values, y=coeff.index, ax=axs[pos])\n",
    "    \n",
    "# for 문 바깥에서 맷플롯립의 show 호출 및 alpha에 따른 피처별 회귀 계수를 DataFrame으로 표시\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7bf10",
   "metadata": {},
   "source": [
    "#### alpha 값에 따른 컬럼별 회귀계수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = [0, 0.1, 1, 10, 100]\n",
    "sort_column = 'alpha:'+str(ridge_alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458bfd14",
   "metadata": {},
   "source": [
    "### 라쏘(L1) 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f041c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W의 절댓값에 페널티를 부여하는 L1 규제를 선형 회귀에 적용한 것이 라쏘(Lasso) 회귀이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b10236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, ElasticNet\n",
    "\n",
    "# alpha값에 따른 회귀 모델의 폴드 평균 RMSE를 출력하고 회귀 계수값들을 DataFrame으로 반환\n",
    "def get_linear_reg_eval(model_name, params=None, X_data_n=None, y_target_n=None, verbose=True):\n",
    "    coeff_df = pd.DataFrame()\n",
    "    if verbose: print('#######', model_name, '#######')\n",
    "    for param in params:\n",
    "        if model_name =='Ridge': model = Ridge(alpha=param)\n",
    "        elif model_name =='Lasso': model = Lasso(alpha=param)\n",
    "        elif model_name =='ElasticNet': model = ElasticNet(alpha=param, l1_ratio=0.7)\n",
    "        neg_mse_scores = cross_val_score(model, X_data_n, y_data_n,\n",
    "                                        scoring=\"neg_mean_squared_error\", cv=5)\n",
    "        avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "        print('alpha {0}일 때 5 폴드 세트의 평균 RMSE: {1:.3f}'.format(param, avg_rmse))\n",
    "        \n",
    "        # alpha에 따른 피처별 회귀 계수를 Series로 변환하고 이를 DataFrame의 컬럼으로 추가.\n",
    "        coeff = pd.Series(data=model.coef_, index=X_data.columns)\n",
    "        colname='alpha:'+str(param)\n",
    "        coeff_df[colname] = coeff\n",
    "    return coeff_df\n",
    "# end of get_linear_regre_eval\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2409e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라쏘에 사용될 alpha 파라미터의 값을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "lasso_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_lasso_df = get_linear_reg_eval('Lasso', params=lasso_alphas, X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd29a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_lasso_df를 첫 번째 컬럼 순으로 내림차순 정렬해 회귀계수 DataFrame 출력\n",
    "sort_column = 'alpha:'+str(lasso_alphas[0])\n",
    "coeff_lasso_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cf440",
   "metadata": {},
   "source": [
    "### 엘라스틱넷 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e4e648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘라스틱넷(Elastic Net) 회귀는 L2 규제와 L1 규제를 결합한 회귀이다.\n",
    "# 엘라스틱넷 회귀 비용함수의 목표는 RSS(W) + alpha2*||W||2^2 + alpha1*||W||1 식을 최소화하는 W를 찾는 것이다.\n",
    "# 엘라스틱넷의 단점은 L1과 L2가 결합된 규제로 인해 수행시간이 상대적으로 오래 걸린다는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1657d72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘라스틱넷에 사용될 alpha 파라미터의 값들을 정의하고 get_linear_reg_eval() 함수 호출\n",
    "# l1_ratio는 0.7로 고정\n",
    "elastic_alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "coeff_elastic_df = get_linear_reg_eval('ElasticNet', params=elastic_alphas,\n",
    "                                      X_data_n=X_data, y_target_n=y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반환된 coeff_elastic_df를 첫번째 컬럼순으로 내림차순 정렬하여 회귀계수 DataFrame출력\n",
    "sort_column = 'alpha:'+str(elastic_alphas[0])\n",
    "coeff_elastic_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b21be6b",
   "metadata": {},
   "source": [
    "### 선형 회귀 모델을 위한 데이터 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff47732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선형 모델은 일반적으로 피처와 타깃값 간에 선형의 관계까 있다고 가정하고,\n",
    "# 최적의 선형함수를 찾아내 결과값을 예측한다.\n",
    "# 피처값과 타깃값의 분포가 종 모양의 정규분포인 형태를 매우 선호한다.\n",
    "# 특히 타깃값의 경우 정규 분포 형태가 아니라 특정값의 분포가 치우친\n",
    "# 왜곡(Skew)된 형태의 분포도일 경우 예측 성능에 부정적인 영향을 미칠 가능성이 높다.\n",
    "# 선형 회귀 모델을 적용하기 전에 먼저 데이터에 대한 스케일링/정규화 작업을 수행하는 것이 일반적이다.\n",
    "# 중요 피처들이나 타깃값의 분포도가 심하게 왜곡됐을 경우에 이러한 변환 작업을 수행한다.\n",
    "# 피처 데이터 세트와 타깃 데이터 세트에 스케일링/정규화 작업을 수행하는 방법이 조금은 다르다.\n",
    "\n",
    "# 피처 세트에 적용하는 변환 작업은\n",
    "# 1. StandardSclaer나 MinMaxScaler를 이용해 정규화를 수행한다.\n",
    "# 2. 개선이 없을 경우 다항 특정을 적용하여 변환한다.\n",
    "# 3. 원래 값에 log 함수를 적용한다. (보다 정규 분포에 가까운 형태로 값이 분포 됨)\n",
    "\n",
    "# 타깃값의 경우 일반적으로 로그 변환을 적용한다.\n",
    "# 결정 값을 정규 분포나 다른 정규값으로 변환하면 변환된 값을 다시 원본 타깃값으로\n",
    "# 원복하기 어려울 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "# method는 표준 정규 분포 변환(Standard), 최대값/최소값 정규화(MinMax), 로그변환(Log) 결정\n",
    "# p_degree는 다향식 특성을 추가할 때 적용. p_degree는 2이상 부여하지 않음. \n",
    "def get_scaled_data(method='None', p_degree=None, input_data=None):\n",
    "    if method == 'Standard':\n",
    "        scaled_data = StandardScaler().fit_transform(input_data)\n",
    "    elif method == 'MinMax':\n",
    "        scaled_data = MinMaxScaler().fit_transform(input_data)\n",
    "    elif method == 'Log':\n",
    "        scaled_data = np.log1p(input_data)\n",
    "    else:\n",
    "        scaled_data = input_data\n",
    "\n",
    "    if p_degree != None:\n",
    "        scaled_data = PolynomialFeatures(degree=p_degree, \n",
    "                                         include_bias=False).fit_transform(scaled_data)\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd3d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge의 alpha값을 다르게 적용하고 다양한 데이터 변환방법에 따른 RMSE 추출. \n",
    "alphas = [0.1, 1, 10, 100]\n",
    "#변환 방법은 모두 6개, 원본 그대로, 표준정규분포, 표준정규분포+다항식 특성\n",
    "# 최대/최소 정규화, 최대/최소 정규화+다항식 특성, 로그변환 \n",
    "scale_methods=[(None, None), ('Standard', None), ('Standard', 2), \n",
    "               ('MinMax', None), ('MinMax', 2), ('Log', None)]\n",
    "for scale_method in scale_methods:\n",
    "    X_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], \n",
    "                                    input_data=X_data)\n",
    "    print(X_data_scaled.shape, X_data.shape)\n",
    "    print('\\n## 변환 유형:{0}, Polynomial Degree:{1}'.format(scale_method[0], scale_method[1]))\n",
    "    get_linear_reg_eval('Ridge', params=alphas, X_data_n=X_data_scaled, \n",
    "                        y_target_n=y_target, verbose=False, return_coeff=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
