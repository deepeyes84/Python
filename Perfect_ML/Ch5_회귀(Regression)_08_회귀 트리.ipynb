{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8a11bfe",
   "metadata": {},
   "source": [
    "##  08 회귀 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a57f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 트리는 회귀를 위한 트리를 생성하고 이를 기반으로 회귀를 예측하는 것이다.\n",
    "# 리프 노드에서 예측 결정 값을 만드는 과정에 차이가 있는데,\n",
    "# 회귀 트리는 리프 노드에 속한 데이터 값의 평균값을 구해 회귀 예측값을 계산한다.\n",
    "\n",
    "# 결정 트리, 랜덤 포레스트, GBM, XGBoost, LightGBM 등의 모든 트리 기반의\n",
    "# 알고리즘은 분류 뿐만 아니라 회귀도 가능하다.\n",
    "# 트리 생성이 CART 알고리즘에 기반하고 있기 때문이다.\n",
    "# CART(Classification And Regression Trees)는 이름에서도 알 수 있듯이\n",
    "# 분류 뿐만 아니라 회귀도 가능하게 해주는 트리 생성 알고리즘이다.\n",
    "\n",
    "# 사이킷런에서는 결정 트리, 랜덤 포레스트, GBM에서 CART 기반의 회귀 수행을\n",
    "# 할 수 있는 Estimator 클래스를 제공한다.\n",
    "# 또한 XGBoost, LightGBM도 사이킷런 래퍼 클래스를 통해 이를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8602aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트 회귀 트리(RandomForestRegressor)를 이용해 보스턴 주택 가격 예측을 수행해보자.\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 보스턴 데이터 세트 로드\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(bostondata, columns = boston.feature_names)\n",
    "\n",
    "bostonDF['PRICE'] = boston.target\n",
    "y_target = bostonDF['PRICE']\n",
    "X_data = bostonDF.drop(['PRICE'], axis=1, inplace=False)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(' 5 교차 검증의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\n",
    "print(' 5 교차 검증의 개별 RMSE scores: ', np.roound(rmse_scores, 2))\n",
    "print(' 5 교차 검증의 평균 RMSE : {0:.3f}'.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 트리, GBM, XGBoost, LightGBM의 Regressor를 모두 이용해보자.\n",
    "\n",
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_Squared_error\", cv=5)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print('#####', model.__class__.__name__, '#####')\n",
    "    print(' 5 교차 검증의 평균 RMSE: {0:.3f}'.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e4d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 회귀 트리를 생성하고, 이를 이용해 보스턴 주택 가격을 예측해보자.\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import GLBMRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_esimators=1000)\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_esimators=1000)\n",
    "lgb_reg = LGBMRegressor(n_esimators=1000)\n",
    "\n",
    "# 트리 기반의 회귀 모델을 반복하면서 평가 수행\n",
    "models = [dt_reg, rf_reg, gb_re, xgb_reg, lgb_reg]\n",
    "for model in models:\n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb440c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 트리 Regressor 클래스는 선형 회귀와 다른 처리 방식이므로 회귀 계수를 제공하는 coef_ 속성이 없다. \n",
    "# 대신 feature_importances_를 이용해 피처별 중요도를 알 수 있다.\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# 앞 예제에서 만들어진 X_data, y_target 데이터 셋을 적용하여 학습한다.\n",
    "rf_reg.fit(X_data, y_target)\n",
    "\n",
    "feature_series = pd.Series(data=rf_reg.feature_importances_, index=X_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x= feature_series, y=feature_series.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 트리 Regressor가 어떻게 예측값을 판단하는지 선형 회귀와 비교해 시각화 해보자.\n",
    "\n",
    "# 결정 트리의 하이퍼 파라미터인 max_depth의 크기를 변화시키면서 어떻게 회귀 트리 예측선이 변화하는지 살펴본다.\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "bostonDF_sample = bostonDF[['RM','PRICE']]\n",
    "bostonDF_sample = bostonDF_sample.sample(n=100, random_state=0)\n",
    "print(bostonDF_sample.shape)\n",
    "plt.figure()\n",
    "plt.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618649c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 선형 회귀와 결정 트리 기반의 Regressor 생성. DecisionTreeRegressor와 max_depth는 각각 2, 7\n",
    "lr_reg = LinearRegression()\n",
    "rf_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "rf_reg7 = DecisionTreeRegressor(max_depth=7)\n",
    "\n",
    "# 실제 예측을 적용할 테스트용 데이터 셋을 4.5 - 8.5 까지 100개 데이터 셋 생성.\n",
    "X_teset = np.arange(4.5, 8.5, 0.04).reshape(-1, 1)\n",
    "\n",
    "# 보스턴 주택가격 데이터에서 시각화를 위해 피처는 RM만, 결정 데이터인 PRICE 추출\n",
    "X_feature = bostonDF_sample['RM'].values.reshape(-1, 1)\n",
    "y_target = bostonDF_sample['PRICE'].values.reshape(-1, 1)\n",
    "\n",
    "# 학습과 예측 수행.\n",
    "lr_reg.fit(X_feature, y_target)\n",
    "rf_reg2.fit(X_feature, y_target)\n",
    "rf_reg7.fit(X_feature, y_target)\n",
    "\n",
    "pred_lr = lr_reg.predict(X_target)\n",
    "pred_rf2 = rf_reg2.predict(X_test)\n",
    "pred_rf7 = rf_reg7.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(figsize=(14, 4), ncols=3)\n",
    "\n",
    "# x축값을 4.5 ~ 8.5로 변환하며 입력했을 때, 선형 회귀와 결정 트리 회귀 예측선 시각화\n",
    "# 선형 회귀로 학습된 모델 회귀 예측선\n",
    "ax1.set_title('Linear Regression')\n",
    "ax1.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax1.plot(X_test, pred_lr,label=\"linear\", linewidth=2)\n",
    "\n",
    "# DecisionTreeRegressor의 max_depth를 2로 했을 때 회귀 예측선\n",
    "ax2.set_title('Decision Tree Regression: \\n max_depth=2')\n",
    "ax2.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax2.plot(X_test, pred_rf2, label=\"max_depth:3\", linewidth=2)\n",
    "\n",
    "# DecisionTreeRegressor의 Max_depth를 7로 했을 때 회귀 예측선\n",
    "ax3.set_title('Decision Tree Regression: \\n max_depth=7')\n",
    "ax3.scatter(bostonDF_sample.RM, bostonDF_sample.PRICE, c=\"darkorange\")\n",
    "ax3.plot(X_test, pred_rf7, label=\"max_depth:7\", linewidth=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
