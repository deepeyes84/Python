{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "328df2ac",
   "metadata": {},
   "source": [
    "## 01 추천시스템의 개요와 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d33bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 많은 전자상거래 업체가 추천 시스템을 도입함으로써 매출을 큰 폭으로 증가시켰으며, 사용자의 쇼핑 즐거움 또한 배가할 수 있었다.\n",
    "# 유투브나 애플 뮤직은 몇 개의 컨텐츠만 클릭하더라도 그와 유사하거나 연관된 컨텐츠가 줄줄이 추천된다.\n",
    "# 이들이 추천하는 것은 대부분 사용자가 관심을 가질 만한 컨텐츠임은 물론이고, 놀랍게도 그동안 잊고 지내왔거나 몰랐던\n",
    "# 새로운 취향의 컨텐츠까지 소개해준다.\n",
    "\n",
    "# 아마존, 이베이 등 유수의 전자상거래 업체가 추천 시스템 도입 후 큰 매출 향상을 경험했다.\n",
    "# 하나의 컨텐츠를 선택했을 때 선택된 컨텐츠와 연관된 추천 컨텐츠가 얼마나 사용자의 관심을 끌고 개인에게 맞춘 컨텐츠를 추천했는지는\n",
    "# 그 사이트의 평판을 좌우하는 매우 중요한 요소이다.\n",
    "\n",
    "# 더 많은 데이터가 추천 시스템에 축적되면서 추천이 더욱 정확해지고 다양한 결과를 얻을 수 있는 좋은 선순환 시스템을 구축할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231f2a4",
   "metadata": {},
   "source": [
    "### 온라인 스토어의 필수 요소, 추천 시스템 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df75b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천 시스템은 특히 온라인에서 그 진가를 발휘한다. \n",
    "# 누구나 한번 쯤은 다양한 상품 이미지와 번잡하 카테고리, 메뉴 구성등으로 인해 온라인상에서 제품 선택의 어려움을 겪었을 것이다.\n",
    "# 이러한 경험이 쌓일수록 온라인 쇼핑에 대한 부정적인 이미지가 강해져 결국 매출 감소로 이어질 수 있다.\n",
    "# 좋은 추천 시스템은 사용자가 무엇을 원하는지 빠르게 찾아내 사용자의 온라인 쇼핑의 즐거움을 배가한다.\n",
    "# 따라서 온라인 스토어에서 추천 시스템은 필수 구성 요소이다.\n",
    "\n",
    "# 온라인 스토어는 많은 양의 고객과 상품 관련 데이터를 가지고 있다. 이 모든 데이터가 사용자가 흥미를 가질 만한 상품을 즉각적으로\n",
    "# 추천 하는데 사용된다.\n",
    "# * 사용자가 어떤 상품을 구마했는가?\n",
    "# * 사용자가 어떤 상품을 둘러보거나 장바구니에 넣었는가?\n",
    "# * 사용자가 평가한 영화 평점은? 제품 평가는?\n",
    "# * 사용자가 스스로 작성한 자신의 취향은?\n",
    "# * 사용자가 무엇을 클릭했는가?\n",
    "\n",
    "# 이러한 데이터를 기반으로 추천 시스템은 사용자가 상품을 구매하도록 유혹한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c13f13",
   "metadata": {},
   "source": [
    "### 추천 시스템의 유형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8a0ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추천시스템은 크게 컨텐츠 기반 필터링(Content Based Filtering) 방식과 협업 필터링(Collaborative Filtering) 방식으로 나뉜다.\n",
    "# 그리고 엽헙 필터링 방식은 다시 최근접 이웃(Nearest Neighbor) 협업 필터링과 잠재 요인(Latent Factor) 협업 필터링으로 나뉜다.\n",
    "\n",
    "# 추천 시스템의 초창기에는 컨텐츠 기반 필터링이나 최근접 이웃 기반 협업 필터링이 주로 사용됐지만, 넷플릭스 추천 시스템 경연 대회에서\n",
    "# 행렬 분해(Matrix Factorization) 기법을 이용한 잠재요인 협업 필털이 방식이 우승하면서 대부분의 온라인 스토에서 \n",
    "# 잠재 요인 협업 필터링 기반의 추천 시스템을 적용하고 있다.\n",
    "# 하지만 서비스 하는 아이템의 특성에 따라 컨텐츠 기반 필터링이나 최근접 이웃 기반 협업 필터링 방식을 유지하는 사이트도 많다.\n",
    "# 요즘에는 개인화 특성을 좀 더 강화하기 위해서 하이브리드 형식으로 컨텐츠 기반과 협업 기반을 적절히 결합해 사용하는 경우도 늘고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759540f3",
   "metadata": {},
   "source": [
    "### 컨텐츠 기반 필터링 추천 시스템 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af05dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 특정한 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 컨텐츠를 가진 다른 아이템을 추천하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325369ed",
   "metadata": {},
   "source": [
    "## 03 최근접 이웃 협업 필터링 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1eb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식(User Behavior)만을 기반으로 추천을 수행하는 것이\n",
    "# 협업 필터링(Collaborative Filtering) 방식이다.\n",
    "# 협업 필터링의 주요 모교는 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 해동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을\n",
    "# 예측 평가(Predicted Rating)하는 것이다.\n",
    "\n",
    "# 협업 필터링 기반의 추천 시스템은 최근접 이웃 방식과 잠재 요인 방식으로 나뉘며, 두 방식 모두 사용자-아이템 평점 행렬 데이터만 의지해 추천을 수행한다.\n",
    "# 헙업 필터링 알고리즘에 사용되는 사용자-아이템 평점 행렬에서 행(Row)은 개별 사용자, 열(Column)은 개별 아이템으로 구성되며,\n",
    "# 사용자 아이디 행, 아이템 아이디 열 위치에 해당하는 값이 평점을 나타내는 형태가 되어야 한다.\n",
    "# 만약 데이터가 레코드 레벨 형태인 로우 레벨 형태의 사용자-아이템 평점 데이터라면 \n",
    "# 판다스의 pivot_table()과 같은 함수를 이용해 사용자(로우)-아이템(컬럼)으로 구성된 사용자-아이템 평점 행렬 형태로 변경해야 한다.\n",
    "# 일반적으로 이러한 사용자-아이템 평점 행렬은 많은 아이템을 열로 가지는 다차원 행렬이며, \n",
    "# 사용자가 아이템에 대한 평점으 메기는 경우가 많지 않기 떄문에 희소 행렬(Sparse Matrix) 특성을 가지고 있다.\n",
    "\n",
    "# 최근접 이웃 협업 필터링은 메모리(Memory) 협업 필터링이라고도 하며, 일반적으로 사용작 기반과 아이템 기반으로 다시 나뉠 수 있다.\n",
    "# * 사용자 기반(User-User): 당신과 비슷한 고객들이 다음 상품도 구매 했습니다.\n",
    "# * 아이템 기반(Item_Item): 이 상품을 선택한 다른 고객들은 다음 상품도 구매했습니다.\n",
    "\n",
    "# 사용자 기반 최근접 이웃 방식은 특정 사용자와 유사한 다른 사용자를 TOP-N 으로 선정해 이 TOP-N 사용자가 좋아하는 아이템을 추천하는 방식이다.\n",
    "# 즉, 특정 사용자와 타 사용자 간의 유사도를 측정한 뒤 가장 유사도 가 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천하는 것이다.\n",
    "\n",
    "# 아이템 기반 최근접 이웃 방식은 아이템이 가지는 속성과 상관없이 사용자들이 그 아이템을 좋아하는지/싫어하는지의 평가 척도가 유사한 아이템을\n",
    "# 추천하는 기준이 되는 알고리즘이다. 사용자 기반 최근접 이웃 데이터 세트와 행과 열이 서로 반대이다.\n",
    "\n",
    "# 일반적으로 사용자 기반보다는 아이템 기반 협업 필터링이 정확도가 더 높다. 이유는 비슷한 영화(상품)를 좋아(구매)한다고 해서\n",
    "# 사람들의 취향이 비슷하다고 판단하기는 어려운 경우가 많기 때문이다.\n",
    "\n",
    "# 최근접 이웃 협업 필터링은 대부분 아이템 기반의 알고리즘을 적용한다.\n",
    "\n",
    "# 유사도 측정 방법인 코사인 유사도는 추천 시스템의 유사도 측정에 가장 많이 적용된다.\n",
    "# 추천 시스템에 사용되는 데이터는 피처 벡터화된 텍스트 데이터와 동일하게 다차원 희소 행렬이라는 특징이 있으므로 \n",
    "# 유사도 측정을 위해 주로 코사인 유사도를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8671b1e",
   "metadata": {},
   "source": [
    "## 04 잠재 요인 협업 필터링 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a9fa0",
   "metadata": {},
   "source": [
    "### 잠재 요인 협업 필터링의 이해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53c26b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠재 요인 헙업 필터링은 사용자-아이템 평점 매트릭스 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 해주는 기법이다.\n",
    "# 대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인을 추출하는데,\n",
    "# 이러한 기법을 행렬 분해(Matrix Factorization)라고 한다.\n",
    "\n",
    "# 잠재 요인 헙업 필터링은 사용자-아이템 평점 행렬 데이터만을 이용해 말 그대로 '잠재 요인'을 끄집어 내는 것을 의미한다.\n",
    "# '잠재 요인'을 기반으로 다차원 희소 행려인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재 요인 행렬과\n",
    "# 아이템-잠자 요인 행렬의 전치 행렬(잠재 요인-아이템 행렬)로 분해할 수 있으며, 이렇게 분해된 두 행렬의 내적을 통해\n",
    "# 새로운 예측 사용자-아이템 평점 행렬 데이터를 만들어서 사용자가 아직 평점을 부여하지 않는 아이템에 대한 예측 평점을\n",
    "# 생성하는 것이 잠재 요인 협력 필터링 알고리즘의 골자이다.\n",
    "\n",
    "# 사용자-잠재 요인 행렬은 사용자의 영화 장르에 대한 선호도로, 아이템-잠재 요인 행렬은 영화의 장르별 특성값으로 정의 할 수 있다.\n",
    "# 평점은 사용자의 장르별 선호도 벡터와 영화의 장르별 특성 벡터를 서로 곱해서 만들 수 있다.\n",
    "\n",
    "# 잠재 요인 협업 필터링은 숨겨져 있는 '잠재 요인'을 기반으로 분해된 매트릭스를 이용해 사용자가 아직 평가하지 않은 아이템에 대한\n",
    "# 예측 평가를 수행하는 것이다. 사용자-아이템 평점 행렬과 같이 다차원의 매트릭스를 저차원의 매트릭스로 분해하는 기법을\n",
    "# 행렬 분해(Matrix Factorization)라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c0666f",
   "metadata": {},
   "source": [
    "### 행렬 분해의 이해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60aee585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 분해는 다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법으로서 대표적으로 SVD(Singular Vector Decompression),\n",
    "# NMF(Non-Negative Matrix Factorization) 등이 있다.\n",
    "# Factorization(분해)는 '인수 분해'를 말한다. 인수분해는 일반적으로 하나의 복잡한 다항식을 두 개 이상의 좀 더 단순한\n",
    "# 인수(factor)의 곱으로 분해하는 것을 말한다.\n",
    "\n",
    "# M개의 사용자(User) 행과 N개의 아이템(Item) 열을 가진 평점 행렬 Rdms M X N 차원으로 구성되며,\n",
    "# 행렬 분해를 통해서 사용자-K 차원 잠재 요인 행렬 P(M X K 차원)와 K 차원 잠재 요인 - 아이템 행렬 Q.T(K X N 차원)으로 분해될 수 있다.\n",
    "# (Q는 아이템-잠재 요인 행렬이며, Q.T는 Q의 전치 행렬인 잠재요인-아이템 행렬)\n",
    "\n",
    "# 행렬 분해는 주로 SVD(Singluar Value Decompression) 방식을 이용한다.\n",
    "# 하지만 SVD는 널(NaN) 값이 없는 행렬에맘ㄴ 적용할 수 있다. R 행렬에는 아직 평점이 되지 않은 많은 널 값이 때문에\n",
    "# P와 Q 행렬을 일반적인 SVD 방식으로는 분해할 수가 없다. 이러한 경우에는 확률적 경사 하강법(Stochastic Gradient Descent:SGD)이나\n",
    "# ALS(Altering Least Squares) 방식을 이용해 SVD를 수행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b00f06",
   "metadata": {},
   "source": [
    "### 확률적 경사 하강법을 이용한 행렬 분해 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b53bdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률적 경사 하강법(Stochastic Gradient Descent)은 경사 하강법의 한 종류이다.\n",
    "# P와 Q 행렬로 계싼된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적인 비용 함수 최적화를 통해\n",
    "# P와 Q를 유추해 내는 것이다.\n",
    "\n",
    "# 확률적 경사 하강법을 이용한 행렬 분해 절차:\n",
    "# 1. P와 Q를 임의의 값을 가진 행렬로 설정한다.\n",
    "# 2. P와 Q.T 값을 곱해 예측 R 행렬을 계산하고 예측 R 행렬과 실제 R 행렬에 대당하는 오류 값을 계산한다.\n",
    "# 3. 이 오류 값을 최소화 할 수 있도록 P와 Q 행렬을 적절한 값으로 각각 업데이트 한다.\n",
    "# 4. 만족할 만한 오류 값을 가질 떄까지 2, 3번 작업을 반복하면서 P와 Q 값을 업데이트해 근사화 한다.\n",
    "\n",
    "# 일반적으로 사용자-아이템 평점 행렬의 경우 행렬 분해를 위해서 단순히 예측 오류값이 최소화와 학습 시 과적합을 피하기 위해서\n",
    "# 규제를 반영한 비용 함수를 적용한다.\n",
    "# 평점 행렬을 경사 하강법을 이용해 행렬 분해하는 것은, L2 규제를 반영해 실제 R 행렬 값과 예측 R 행렬 값의 차이를 최소화 하는\n",
    "# 방향성을 가지고 P 행렬과 Q 행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R 행렬을 구하는 방식이 SGD 기반의 행렬 분해이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf1fabee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD를 이용해 행렬 분해를 수행하는 예제를 구현해보자.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정.\n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
    "             [np.NaN, 5, np.NaN, 3, 1],\n",
    "             [np.NaN, np.NaN, 3, 4, 4],\n",
    "             [5, 2, 1, 2, np.NaN]])\n",
    "num_users, num_items = R.shape\n",
    "K=3\n",
    "\n",
    "# P와 Q 행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력한다.\n",
    "np.random.seed(1)\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da95cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 R 행렬과 예측 행렬의 오차를 구하는 get_rmse() 함수를 만들어보자.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99528590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  3.2127085854479995\n",
      "### iteration step :  50  rmse :  0.4717115241193164\n",
      "### iteration step :  100  rmse :  0.160297539983668\n",
      "### iteration step :  150  rmse :  0.07923591286254614\n",
      "### iteration step :  200  rmse :  0.046971203124945696\n",
      "### iteration step :  250  rmse :  0.03192737809812918\n",
      "### iteration step :  300  rmse :  0.024473944400935383\n",
      "### iteration step :  350  rmse :  0.020787126083446992\n",
      "### iteration step :  400  rmse :  0.018976115212698413\n",
      "### iteration step :  450  rmse :  0.018071766235615287\n",
      "### iteration step :  500  rmse :  0.017601254826932658\n",
      "### iteration step :  550  rmse :  0.017341328492760797\n",
      "### iteration step :  600  rmse :  0.017186163825892324\n",
      "### iteration step :  650  rmse :  0.01708426961927116\n",
      "### iteration step :  700  rmse :  0.017009784793227463\n",
      "### iteration step :  750  rmse :  0.016949374001989675\n",
      "### iteration step :  800  rmse :  0.01689605302310692\n",
      "### iteration step :  850  rmse :  0.016846157007123656\n",
      "### iteration step :  900  rmse :  0.01679779199038616\n",
      "### iteration step :  950  rmse :  0.016750018304829653\n"
     ]
    }
   ],
   "source": [
    "# SGD 기반으로 행렬 분해를 수행하자.\n",
    "\n",
    "# R > 0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장.\n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "\n",
    "steps=1000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트. \n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros:\n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate*(eij * Q[j, :] - r_lambda*P[i,:])\n",
    "        Q[j,:] = Q[j,:] + learning_rate*(eij * P[i, :] - r_lambda*Q[j,:])\n",
    "\n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c4be0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 행렬:\n",
      " [[3.99  0.784 1.341 2.003 1.729]\n",
      " [6.702 4.978 0.953 2.98  1.003]\n",
      " [6.933 0.42  2.987 3.976 3.986]\n",
      " [4.968 2.005 1.007 2.018 1.163]]\n"
     ]
    }
   ],
   "source": [
    "# 분해된 P와 Q 함수를 P*Q.T 로 예측 행렬을 만들어서 출력해보자.\n",
    "\n",
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본행렬과 비교해 널이 아닌 값은 큰 차이가 나지 않았으며, 널인 값은 새로운 예측값으로 채워졌다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
